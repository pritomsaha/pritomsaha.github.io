---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

You can also find the publications on [my Google Scholar profile](https://scholar.google.com/citations?user=mBDDbmEAAAAJ)    
(*equal contribution)

### 2024
1. **Pritom Saha Akash**, Kevin Chen-Chuan Chang. Prefix-VAE: Efficient and Consistent Short-Text Topic Modeling with LLMs. Findings of the 2024 Conference on Empirical Methods in Natural Language Processing **(EMNLP Findings)**}. 2024.
2. Kashob Kumar Roy, **Pritom Saha Akash**, Lucian Popa, and Kevin Chen-Chuan Chang. ConTReGen: Context-driven Tree-structured Retrieval for Open-domain Long-form Text Generation. Findings of the 2024 Conference on Empirical Methods in Natural Language Processing **(EMNLP Findings)**. 2024.

### 2023
1. Lam Do, **Pritom Saha Akash**, Kevin Chen-Chuan Chang. Unsupervised Open-domain Keyphrase Generation. The 61st Annual Meeting of the Association for Computational Linguistics **(ACL)**. 2023.
2. **Pritom Saha Akash**, Jie Huang, and Kevin Chen-Chuan Chang. Let the Pretrained Language Models ``Imagine'' for Short Texts Topic Modeling. arXiv preprint arXiv:2310.15420 (2023). [[pdf](https://arxiv.org/pdf/2310.15420)]
3. **Pritom Saha Akash***, Kashob Kumar Roy*, Lucian Popa, and Kevin Chen-Chuan Chang. Long-form Question Answering: An Iterative Planning-Retrieval-Generation Approach. arXiv preprint arXiv:2311.09383 (2023). [[pdf](https://arxiv.org/pdf/2311.09383)]
4. **Pritom Saha Akash**\*, Trisha Das*, and Kevin Chen-Chuan Chang. TopicAdapt-An Inter-Corpora Topics Adaptation Approach. arXiv preprint arXiv:2310.04978 (2023). [[pdf](https://arxiv.org/pdf/2310.04978)]

### 2022
1. **Pritom Saha Akash**, Jie Huang, Kevin Chen-Chuan Chang. Coordinated Topic Modeling. The 2022 Conference on Empirical Methods in Natural Language Processing **(EMNLP)**. 2022.
2. **Pritom Saha Akash**, Jie Huang, Kevin Chen-Chuan Chang, Yunyao Li, Lucian Popa, ChengXiang Zhai. Domain Representative Keywords Selection: A Probabilistic Approach. Findings of the 60th Annual Meeting of the Association for Computational Linguistics **(ACL Findings)**. 2022.

### 2021
1. **Pritom Saha Akash**, Kevin Chen-Chuan Chang. Exploring Variational Graph Auto-Encoders for Extract Class Refactoring Recommendation. arXiv preprint arXiv:2203.08787 (2021). [[pdf](https://arxiv.org/pdf/2203.08787.pdf)]
2. **Pritom Saha Akash**, Wei-Cheng Lai, Po-Wen Lin. Online Aggregation based Approximate Query Processing: A Literature Survey. arXiv preprint arXiv:2204.07125 (2021). [[pdf](https://arxiv.org/pdf/2204.07125.pdf)]

### 2020
1. Md. Eusha Kadir, **Pritom Saha Akash**, Sadia Sharmin, Amin Ahsan Ali, and Mohammad Shoyaib. A Proximity Weighted Evidential k Nearest Neighbor Classifier for Imbalanced Data. In Pacific-Asia Conference on Knowledge Discovery and Data Mining, **(PAKDD)** pp. 71-83. Springer, Cham, 2020.
2. Tarek, M. H., Kadir, M. E., Mahbub, M., **Pritom Saha Akash**, Ali, A. A., & Shoyaib, M. (2020, August). Mutual Information based feature selection for nurse care activity recognition. In 2020 Joint 9th International Conference on Informatics, Electronics & Vision (ICIEV) and 2020 4th International Conference on Imaging, Vision \& Pattern Recognition (icIVPR) (pp. 1-6). IEEE.

### 2019
1. Md. Eusha Kadir\*, **Pritom Saha Akash**\*, Sadia Sharmin, Amin Ahsan Ali, and Mohammad Shoyaib. Can a Simple Approach Identify Complex Nurse Care Activity? In Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the 2019 International Symposium on Wearable Computers **(UbiComp/ISWC Adjunct)**. 2019.
2. **Pritom Saha Akash**, Md. Eusha Kadir, Amin Ahsan Ali and Mohammad Shoyaib. Inter-node Hellinger distance based Decision Tree. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, **(IJCAI)**, 2019.
3. **Pritom Saha Akash**\*, Md. Eusha Kadir, Amin Ahsan Ali, Md. Nurul Ahad Tawhid and Mohammad Shoyaib. Introducing Confidence as a Weight in Random Forest. 2019 International Conference on Robotics, Electrical and Signal Processing Techniques (ICREST). (\*Best Presenter)
4. **Pritom Saha Akash**, Ali Zafar Sadiq and Ahmedul Kabir. An Approach of Extracting God Class Exploiting Both Structural and Semantic Similarity. 14th International Conference on Evaluation of Novel Approaches to Software Engineering **(ENASE)**. 2019.
5. Jeba, Tahmim, Tarek Mahmud, **Pritom Saha Akash**, and Nadia Nahar. God Class Refactoring Recommendation and Extraction Using Context based Grouping.
6. Md. Eusha Kadir, **Pritom Saha Akash**, Amin Ahsan Ali, Mohammad Shoyaib and Zerina Begum, ”Evidential SVM for binary classification”, ICASERT-2019: 1st International Conference on Advances in Science, Engineering and Robotics Technology.
7. Ali Zafar Sadiq, Ahmedul Kabir, **Pritom Saha Akash** and Md. Jubair Ibna Mostafa. Analyzing Corrective Maintenance using Change Coupled Clusters at Fix-inducing Changes. 2019 International Conference on Electrical, Computer and Communication Engineering (ECCE).


<!-- 
### Preprints
1. **Pritom Saha Akash**, Jie Huang, and Kevin Chen-Chuan Chang. Let the Pretrained Language Models ``Imagine'' for Short Texts Topic Modeling. arXiv preprint arXiv:2310.15420 (2023). [[pdf](https://arxiv.org/pdf/2310.15420)]
2. **Pritom Saha Akash***, Kashob Kumar Roy*, Lucian Popa, and Kevin Chen-Chuan Chang. Long-form Question Answering: An Iterative Planning-Retrieval-Generation Approach. arXiv preprint arXiv:2311.09383 (2023). [[pdf](https://arxiv.org/pdf/2311.09383)]
3. **Pritom Saha Akash**\*, Trisha Das*, and Kevin Chen-Chuan Chang. TopicAdapt-An Inter-Corpora Topics Adaptation Approach. arXiv preprint arXiv:2310.04978 (2023). [[pdf](https://arxiv.org/pdf/2310.04978)]
4. **Pritom Saha Akash**, Kevin Chen-Chuan Chang. Exploring Variational Graph Auto-Encoders for Extract Class Refactoring Recommendation. arXiv preprint arXiv:2203.08787 (2021). [[pdf](https://arxiv.org/pdf/2203.08787.pdf)]
5. **Pritom Saha Akash**, Wei-Cheng Lai, Po-Wen Lin. Online Aggregation based Approximate Query Processing: A Literature Survey. arXiv preprint arXiv:2204.07125 (2021). [[pdf](https://arxiv.org/pdf/2204.07125.pdf)]
-->
